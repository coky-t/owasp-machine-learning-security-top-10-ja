---
layout: col-sidebar
type: documentation
altfooter: true
level: 4
auto-migrated: 0
document: OWASP Machine Learning Security Top Ten 2023
year: 2023
order: 5
title: ML05:2023 Model Stealing (モデル盗用)
lang: ja
tags:
  [
    OWASP Machine Learning Security Top Ten 2023,
    Top Ten,
    ML05:2023,
    mltop10,
    mlsectop10,
  ]
exploitability: 4
detectability: 3
technical: 4
---

## 説明

モデル盗用攻撃は攻撃者がモデルのパラメータにアクセスできるようになることで発生します。


## 防止方法

**暗号化:** モデルのコード、訓練データ、その他の機密情報を暗号化することで、攻撃者がモデルにアクセスして盗み出すことを防止できます。


**アクセス制御:** 二要素認証などの厳格なアクセス制御対策を実装することで、認可されていない個人がモデルにアクセスして盗み出すことを防止できます。



**定期的なバックアップ:** モデルのコード、訓練データ、その他の機密情報を定期的にバックアップすることで、盗難が発生した場合でも確実に復元できます。



**モデルの難読化:** モデルのコードを難読化してリバースエンジニアリングを困難にすることで、攻撃者がモデルを盗み出すことを防止できます。


**電子透かし:** モデルのコードと訓練データに電子透かしを入れることで、盗用元を追跡し、攻撃者に責任を追及できます。



**法的保護:** 特許や企業秘密などのモデルの法的保護を確保することで、攻撃者がモデルを盗み出すことをより困難にし、盗難が発生した場合には法的措置の根拠とできます。



**監視と監査:** モデルの使用を定期的に監視し監査することで、攻撃者がモデルへのアクセスや盗難を試みていることを検知して、盗難の検知と防止に役立ちます。



## リスク要因

| 脅威エージェント/攻撃手法 | セキュリティ上の弱点 | 影響 |
| :-----------------------: | :------------------: | :--: |
| 悪用難易度: 4 (普通) <br><br> _ML アプリケーション依存: 4_ <br> _ML オペレーション依存: 3_ | 検出難易度: 3 (普通) | 技術的影響: 4 (普通) |
| 脅威エージェント: これは攻撃を実行する主体であり、この場合、機械学習モデルを盗み出そうとする攻撃者のことです。 | 安全でないモデルのデプロイメント: モデルの安全でないデプロイメントにより、攻撃者がモデルにアクセスして盗み出すことが容易になります。 | モデル盗用の影響はモデルの訓練に使用されたデータの機密性とモデルを開発した組織の評判の両方に及ぶ可能性があります。 |

本チャートは [下記のシナリオ](#scenario1) に基づくサンプルに過ぎないことに注意することが重要です。
実際のリスク評価は各機械学習システムの具体的な状況によって異なります。


## 攻撃シナリオの例

### シナリオ \#1: 競合他社から機械学習モデルを盗み出す {#scenario1}

悪意のある攻撃者は価値のある機械学習モデルを開発した会社の競合他社に勤務しています。
攻撃者は会社が競争上の優位を獲得し、自社の目的に使用できるようにするために、このモデルを盗み出そうと考えています。



攻撃者はバイナリコードを逆アセンブルするか、モデルの訓練データとアルゴリズムにアクセスして、同社の機械学習モデルをリバースエンジニアリングすることで、この攻撃を実行しました。
いったんモデルをリバースエンジニアリングすると、攻撃者はこの情報を使用してモデルを再作成し、それを自社の目的に使用できるようになります。
その結果、元の会社には多大な経済的損失が発生するだけでなく、評判も損なわれる可能性があります。




## 参考資料
