---
layout: col-sidebar
type: documentation
altfooter: true
level: 4
auto-migrated: 0
document: OWASP Machine Learning Security Top Ten 2023
year: 2023
order: 2
title: ML02:2023 Data Poisoning Attack (データポイズニング攻撃)
lang: ja
tags:
  [
    OWASP Machine Learning Security Top Ten 2023,
    Top Ten,
    ML02:2023,
    mltop10,
    mlsectop10,
  ]
exploitability: 3
detectability: 2
technical: 4
---

## 説明

データポイズニング攻撃は攻撃者が訓練データを操作してモデルが望ましくない動作をするように仕向けることで発生します。


## 防止方法

**データの妥当性確認と検証:** モデルの訓練に使用する前に訓練データの徹底的に妥当性確認し検証することを確保します。
これはデータバリデーションチェックを実装し、複数のデータラベル付け器を使用してデータラベリングの正確性を確認することで実現できます。



**安全なデータの保存:** 訓練データは暗号化、安全なデータ転送プロトコル、ファイアウォールなどの安全な方法で保存します。


**データの分離:** 訓練データと本番データを分離して訓練データが危殆化するリスクを軽減します。


**アクセス制御:** アクセス制御を実装して訓練データにアクセスできる人とアクセスできるタイミングを制限します。


**監視と監査:** 訓練データに異常がないか定期的に監視し、監査を実施してデータの改竄を検知します。


**モデルバリデーション:** 訓練時に使用していない別のバリデーションセットを使用してモデルを確認します。
これは訓練データに影響を与えた可能性があるデータポイズニング攻撃を検知するのに役立ちます。


**モデルアンサンブル:** 訓練データの異なるサブセットを使用して複数のモデルを訓練し、これらのモデルのアンサンブルを使用して予測を行います。
これにより、攻撃者が目的を達成するには複数のモデルを侵害する必要があるため、データポイズニング攻撃の影響を軽減できます。



**異常検知:** 異常検知技法を使用して、データ分布やデータラベリングの急激な変化などの訓練データの異常な動作を検知します。
これらの技法を使用して、データポイズニング攻撃を早期に検知できます。



## リスク要因

| 脅威エージェント/攻撃手法 | セキュリティ上の弱点 | 影響 |
| :-----------------------: | :------------------: | :--: |
| 悪用難易度: 3 (普通) <br><br> _ML アプリケーション依存: 4_ <br> _ML オペレーション依存: 3_ | 検出難易度: 2 (困難) | 技術的影響: 4 (普通) |
| 脅威エージェント: モデルに使用する訓練データにアクセスできる攻撃者。 <br><br> 攻撃手法: 撃者は訓練データセットに悪意のあるデータを注入します。 | データバリデーションの欠如と訓練データの不十分な監視。 | モデルは汚染されたデータに基づいて誤った予測を行い、誤った判断を下して深刻な事態を招く可能性があります。 |

本チャートは [下記のシナリオ](#scenario1) に基づくサンプルに過ぎないことに注意することが重要です。
実際のリスク評価は各機械学習システムの具体的な状況によって異なります。


## 攻撃シナリオの例

### シナリオ \#1: スパム分類器のトレーニング {#scenario1}

攻撃者は電子メールをスパムかスパムでないかに分類するディープラーニングモデルの訓練データを汚染します。
攻撃者は悪意を持ってラベル付けされたスパムメールを訓練データセットに注入することでこの攻撃を実行しました。
これはたとえばネットワークをハッキングしたりデータストレージソフトウェアの脆弱性を悪用するなどして、データストレージシステムを侵害することで行うことができます。
攻撃者は電子メールのラベル付けを改竄したりデータラベル付け担当者に賄賂を渡して誤ったラベルを提供するなど、データのラベル付けプロセスを操作することも可能です。




### シナリオ \#2: ネットワークトラフィック分類システムのトレーニング

攻撃者はネットワークトラフィックを電子メール、ウェブブラウザ、動画ストリーミングなどのさまざまなカテゴリに分類するために使用されるディープラーニングモデルの訓練データを汚染します。
攻撃者は別のタイプのトラフィックであると誤ったラベル付けをされたネットワークトラフィックの事例を大量に導入し、このトラフィックを誤ったカテゴリに分類するようにモデルを訓練させます。
その結果、このモデルがデプロイされた際に誤ったトラフィック分類を行うように訓練されており、ネットワークリソースの不適切な割り当てやネットワークパフォーマンスの低下につながる可能性があります。






## 参考資料
